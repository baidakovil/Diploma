{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio\n",
    "# !pip install pandas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keylist_fifteen</th>\n",
       "      <th>subs_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['android', 'spaceopera', 'rebellion', 'planet...</td>\n",
       "      <td>['hear', 'shut', 'main', 'reactor', 'destroy',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['basedonnovel', 'love', 'friendship', 'flashb...</td>\n",
       "      <td>['hello', 'name', 'forrest', 'forrest', 'gump'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['nudity', 'femalenudity', 'malenudity', 'comi...</td>\n",
       "      <td>['need', 'father', 'role', 'model', 'horny', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['murder', 'friendship', 'smalltown', 'robbery...</td>\n",
       "      <td>['sweat', 'know', 'im', 'excite', 'though', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['love', 'alien', 'newyorkcity', 'future', 'sh...</td>\n",
       "      <td>['come', 'come', 'please', 'aziz', 'aziz', 'az...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>['murder', 'sex', 'nudity', 'suspense', 'femal...</td>\n",
       "      <td>['hi', 'adrian', 'viktor', 'remember', 'cave',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>['artist', 'painting', 'art', 'resistance', 'c...</td>\n",
       "      <td>['present', 'afterimage', 'star', 'come', 'lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>['chicago', 'coma', 'immigrant', 'arrangedmarr...</td>\n",
       "      <td>['keep', 'go', 'next', 'performer', 'man', 'mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>['violence', 'dog', 'postapocalyptic', 'forest...</td>\n",
       "      <td>['music', 'play', 'heavy', 'breathe', 'sarah',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>['violence', 'police', 'kidnapping', 'gore', '...</td>\n",
       "      <td>['chatter', 'laugh', 'bird', 'twitter', 'bird'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1315 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        keylist_fifteen   \n",
       "0     ['android', 'spaceopera', 'rebellion', 'planet...  \\\n",
       "1     ['basedonnovel', 'love', 'friendship', 'flashb...   \n",
       "2     ['nudity', 'femalenudity', 'malenudity', 'comi...   \n",
       "3     ['murder', 'friendship', 'smalltown', 'robbery...   \n",
       "4     ['love', 'alien', 'newyorkcity', 'future', 'sh...   \n",
       "...                                                 ...   \n",
       "1310  ['murder', 'sex', 'nudity', 'suspense', 'femal...   \n",
       "1311  ['artist', 'painting', 'art', 'resistance', 'c...   \n",
       "1312  ['chicago', 'coma', 'immigrant', 'arrangedmarr...   \n",
       "1313  ['violence', 'dog', 'postapocalyptic', 'forest...   \n",
       "1314  ['violence', 'police', 'kidnapping', 'gore', '...   \n",
       "\n",
       "                                              subs_text  \n",
       "0     ['hear', 'shut', 'main', 'reactor', 'destroy',...  \n",
       "1     ['hello', 'name', 'forrest', 'forrest', 'gump'...  \n",
       "2     ['need', 'father', 'role', 'model', 'horny', '...  \n",
       "3     ['sweat', 'know', 'im', 'excite', 'though', 's...  \n",
       "4     ['come', 'come', 'please', 'aziz', 'aziz', 'az...  \n",
       "...                                                 ...  \n",
       "1310  ['hi', 'adrian', 'viktor', 'remember', 'cave',...  \n",
       "1311  ['present', 'afterimage', 'star', 'come', 'lat...  \n",
       "1312  ['keep', 'go', 'next', 'performer', 'man', 'mr...  \n",
       "1313  ['music', 'play', 'heavy', 'breathe', 'sarah',...  \n",
       "1314  ['chatter', 'laugh', 'bird', 'twitter', 'bird'...  \n",
       "\n",
       "[1315 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_kw_subs.csv', sep=';')\n",
    "df = df.astype({'subs_text': 'string'})\n",
    "df = df.drop('imdb_id', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sub_words=set()\n",
    "for sub in df.subs_text:\n",
    "   for word in eval(sub):\n",
    "       if word not in all_sub_words:\n",
    "           all_sub_words.add(word)\n",
    "\n",
    "all_kw_words=set()\n",
    "for keylist in df.keylist_fifteen:\n",
    "   for word in eval(keylist):\n",
    "       if word not in all_kw_words:\n",
    "           all_kw_words.add(word)\n",
    "\n",
    "input_words = sorted(list(all_sub_words))\n",
    "target_words = sorted(list(all_kw_words))\n",
    "num_encoder_tokens = len(all_sub_words)\n",
    "num_decoder_tokens = len(all_kw_words)\n",
    "\n",
    "input_token_index = dict(\n",
    "   [(word, i) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict(\n",
    "   [(word, i) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#  ?\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m n_class \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(word_dict)\n\u001b[1;32m      3\u001b[0m n_step \u001b[39m=\u001b[39m n_class \u001b[39m# number of cells(= number of Step)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m n_hidden \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m \u001b[39m# number of hidden units in one cell\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#  ?\n",
    "n_class = len(num_dic)\n",
    "n_step = n_class # number of cells(= number of Step)\n",
    "n_hidden = 128 # number of hidden units in one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "\n",
    "    input_batch, output_batch, target_batch = [], [], []\n",
    "    # ?\n",
    "    # n_step = 1 \n",
    "\n",
    "    for seq in seq_data:\n",
    "        for i in range(2):\n",
    "            seq[i] = seq[i] + 'P' * (n_step - len(seq[i]))\n",
    "\n",
    "        input = [num_dic[n] for n in seq[0]]\n",
    "        output = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]\n",
    "\n",
    "        input_batch.append(np.eye(n_class)[input])\n",
    "        output_batch.append(np.eye(n_class)[output])\n",
    "        target_batch.append(target) # not one-hot\n",
    "\n",
    "    # make tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.fc = nn.Linear(n_hidden, n_class)\n",
    "\n",
    "    def forward(self, enc_input, enc_hidden, dec_input):\n",
    "        enc_input = enc_input.transpose(0, 1) # enc_input: [max_len(=n_step, time step), batch_size, n_class]\n",
    "        dec_input = dec_input.transpose(0, 1) # dec_input: [max_len(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_states : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        _, enc_states = self.enc_cell(enc_input, enc_hidden)\n",
    "        # outputs : [max_len+1(=6), batch_size, num_directions(=1) * n_hidden(=128)]\n",
    "        outputs, _ = self.dec_cell(dec_input, enc_states)\n",
    "\n",
    "        model = self.fc(outputs) # model : [max_len+1(=6), batch_size, n_class]\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "\n",
    "for epoch in range(5000):\n",
    "    # make hidden shape [num_layers * num_directions, batch_size, n_hidden]\n",
    "    hidden = torch.zeros(1, batch_size, n_hidden)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # input_batch : [batch_size, max_len(=n_step, time step), n_class]\n",
    "    # output_batch : [batch_size, max_len+1(=n_step, time step) (becase of 'S' or 'E'), n_class]\n",
    "    # target_batch : [batch_size, max_len+1(=n_step, time step)], not one-hot\n",
    "    output = model(input_batch, hidden, output_batch)\n",
    "    # output : [max_len+1, batch_size, n_class]\n",
    "    output = output.transpose(0, 1) # [batch_size, max_len+1(=6), n_class]\n",
    "    loss = 0\n",
    "    for i in range(0, len(target_batch)):\n",
    "        # output[i] : [max_len+1, n_class, target_batch[i] : max_len+1]\n",
    "        loss += criterion(output[i], target_batch[i])\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch, output_batch, _ = make_batch()\n",
    "\n",
    "# make hidden shape [num_layers * num_directions, batch_size, n_hidden]\n",
    "hidden = torch.zeros(1, 6, 128)\n",
    "for i in range(0, len(input_batch)):\n",
    "    output = model(input_batch, hidden, output_batch)\n",
    "    # output : [max_len+1(=6), batch_size(=1), n_class]\n",
    "\n",
    "    output = output.transpose(0, 1)\n",
    "    output = torch.argmax(output.data, -1)[i].numpy()\n",
    "\n",
    "    decode = [char_arr[c] for c in output]\n",
    "\n",
    "    end = decode.index('E')\n",
    "    translated = ''.join(decode[:end])\n",
    "\n",
    "    input_word = [char_arr[w] for w in input_batch[i].max(-1)[1]]\n",
    "    input_word = ''.join(input_word[:end])\n",
    "    print(f\"{input_word.replace('P', '')} -> {translated.replace('P', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
