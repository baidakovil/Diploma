{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import operator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка списка фильмов с ключевыми словами"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подготовка датафрейма с метаданными фильмов (без ключевых слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка исходного датафрейма с метаданными фильмов, удаление пустых и ложных записей, удаление дупликатов, приведение к типам\n",
    "\n",
    "df_meta = pd.read_csv('./moviesdataset/movies_metadata.csv',low_memory=False)\n",
    "df_meta = df_meta.loc[:,['title','id','imdb_id']]\n",
    "\n",
    "\n",
    "df_meta = df_meta.dropna(subset='imdb_id')\n",
    "df_meta = df_meta.drop_duplicates(subset='imdb_id')\n",
    "df_meta = df_meta.drop_duplicates(subset='id')\n",
    "df_meta = df_meta.drop(df_meta[df_meta['id'].str.contains('-')].index)\n",
    "df_meta['imdb_id'] = df_meta['imdb_id'].apply(lambda x: x.replace('tt',''))\n",
    "\n",
    "\n",
    "df_meta = df_meta.astype({'title': 'string', 'id': 'int32','imdb_id': 'int32'})\n",
    "df_meta = df_meta.set_index('id')\n",
    "\n",
    "df_meta.dtypes\n",
    "df_meta.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подготовка датафрейма с ключевыми словами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка исходного датафрейма с ключевыми словами, приведение к типам\n",
    "\n",
    "df_kw = pd.read_csv('./moviesdataset/keywords.csv')\n",
    "df_kw = df_kw.astype({'id': 'int32','keywords': 'string'})\n",
    "df_kw = df_kw.drop_duplicates(subset='id')\n",
    "\n",
    "df_kw = df_kw.set_index('id')\n",
    "df_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обращение ключевых слов dict -> list для удобства работы, подчёт кол-ва ключевых слов в каждом фильме\n",
    "\n",
    "def get_kw_list(data):\n",
    "    \n",
    "    kw_list = [kw['name'].replace(\" \",\"\").replace(\"\\xa0\",\"\").replace(\"'\",\"\") for kw in eval(data)]\n",
    "    return kw_list\n",
    "\n",
    "df_kw.loc[:,'keylist'] = df_kw['keywords'].apply(get_kw_list)\n",
    "df_kw['keywords_len'] = df_kw['keylist'].apply(len)\n",
    "# df_kw = df_kw.drop(['keywords'],axis=1)\n",
    "# df_kw.iloc[0,:]['keylist']\n",
    "# df_kw = df_kw.iloc[:,:][df_kw['keywords_len'] >= 15]\n",
    "df_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление строк без ключевых слов\n",
    "\n",
    "df_kw = df_kw[df_kw['keylist'].apply(len) != 0]\n",
    "\n",
    "df_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовка частотного словаря ключевых слов\n",
    "def get_kw_counts(column):\n",
    "\n",
    "    kw_series = pd.Series([i for j in column.tolist() for i in j])\n",
    "\n",
    "    kw_count = kw_series.value_counts()\n",
    "\n",
    "    counts = pd.DataFrame({'kw':kw_count.index,'count': kw_count})\n",
    "\n",
    "    counts = counts.drop_duplicates(subset='kw')\n",
    "    counts = counts.sort_values(by=['count','kw'], ascending=[False, True])\n",
    "\n",
    "    kw_quantity = len(counts)\n",
    "    will_deleted = len(counts[counts['count']==1])\n",
    "\n",
    "    print(f'Ключевых слов, встречающихся однажды: {will_deleted} ({round(will_deleted/kw_quantity*100,3)}%)')\n",
    "\n",
    "    return counts\n",
    "\n",
    "counts = get_kw_counts(df_kw['keylist'])\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_kw_stat(column):\n",
    "    counts = get_kw_counts(column)\n",
    "    most_popular_count = counts.iloc[0,:]['count']\n",
    "    most_popular_kw = counts.iloc[0,:]['kw']\n",
    "    most_rare_count = counts.iloc[-1,:]['count']\n",
    "    most_rare_kw = counts.iloc[-1,:]['kw']\n",
    "    print(f'Самое популярное слово: {most_popular_kw}, {most_popular_count} раз')\n",
    "    print(f'Самое редкое слово: {most_rare_kw}, {most_rare_count} раз')\n",
    "    print(f'Всего слов: {len(counts)}')\n",
    "\n",
    "print_kw_stat(df_kw['keylist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление тех ключевых слов, которые встречаются только однажды\n",
    "\n",
    "counts_first = get_kw_counts(df_kw['keylist'])\n",
    "onlyonemeet_first = counts_first[counts_first['count'] == 1]['kw']\n",
    "\n",
    "def kw_del_onlyonemeet(keylist):\n",
    "\n",
    "    kw_list = []\n",
    "\n",
    "    for kw in keylist:\n",
    "        if kw in onlyonemeet_first:\n",
    "            pass\n",
    "        else:\n",
    "            kw_list.append(kw)\n",
    "    \n",
    "    return kw_list\n",
    "\n",
    "df = df_kw.copy(deep=True)\n",
    "df['keylist_nolonely'] = df.loc[:,'keylist'].apply(kw_del_onlyonemeet)\n",
    "\n",
    "counts_second = get_kw_counts(df['keylist_nolonely'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбор не более 15 ключевых слов (удалением наиболее редких)\n",
    "\n",
    "counts = get_kw_counts(df['keylist_nolonely'])\n",
    "quantity = 15\n",
    "\n",
    "def get_most_common(keylist):\n",
    "\n",
    "    kw_list = keylist\n",
    "\n",
    "    if len(kw_list) > quantity:\n",
    "\n",
    "        kw_cleaned = {}\n",
    "\n",
    "        for kw in kw_list:\n",
    "            kw_cleaned[kw] = counts[counts['kw'] == kw]['count'].values[0]\n",
    "\n",
    "        most_common = [kw[0] for kw in sorted(kw_cleaned.items(), key=operator.itemgetter(1), reverse=True)[:quantity]]\n",
    "        \n",
    "        return most_common\n",
    "\n",
    "    else:\n",
    "        return keylist   \n",
    "\n",
    "df['keylist_fifteen'] = df['keylist_nolonely'].apply(get_most_common)\n",
    "df['keywords_len_commons'] = df['keylist_fifteen'].apply(len)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбор не менее 15 слов \n",
    "\n",
    "df = df[df['keywords_len_commons'] == 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединение с датасетом с метаданными (для получения названий)\n",
    "df_joined = df.join(df_meta, on='id')\n",
    "df_joined.loc[:,['keylist_fifteen','title','imdb_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_joined.set_index('imdb_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subloaded = pd.read_csv('fil_sub_download_temp_file.csv', sep=';', names=['imdb_id','moviename', 'data','file'])\n",
    "df_subloaded = df_subloaded.astype({'imdb_id': 'int32','moviename': 'string','data': 'object','file': 'object'})\n",
    "df_subloaded = df_subloaded.drop_duplicates(subset='imdb_id')\n",
    "df_subloaded = df_subloaded.drop(df_subloaded[df_subloaded['moviename'] == 'ERROR'].index)\n",
    "df_subloaded = df_subloaded.set_index('imdb_id')\n",
    "df_subloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doned = df_subloaded.join(df_joined, on='imdb_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doned = df_doned.loc[:,['keylist_fifteen']]\n",
    "df_doned.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doned.to_csv('df_keylist_fifteen.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
