{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonopensubtitles.opensubtitles import OpenSubtitles\n",
    "from pythonopensubtitles.utils import File\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtitles_by_id(imdbid):\n",
    "\n",
    "    data = ost.search_subtitles([{'sublanguageid': 'eng','imdbid': imdbid}])\n",
    "\n",
    "    try:\n",
    "        first_sub_data = data[0]\n",
    "        id_subtitle_file = first_sub_data.get('IDSubtitleFile')\n",
    "        moviename = first_sub_data.get('MovieName')\n",
    "        downloaded = ost.download_subtitles([id_subtitle_file], \n",
    "                                output_directory='/home/eva/Diploma/os/',\n",
    "                                override_filenames={id_subtitle_file:f'{imdbid}.srt'})\n",
    "\n",
    "        if downloaded is None:\n",
    "            print(f'Subs for {moviename}, imdb_id {imdbid} not dloaded')\n",
    "            moviename, first_sub_data, downloaded = 'NONNEE', 'NONNE', 'NONNE'\n",
    "\n",
    "    except:\n",
    "        print(f'While dloading subs for imdb_id {imdbid} I got error')\n",
    "        moviename, first_sub_data, downloaded = 'ERROR', 'ERROR', 'ERROR'\n",
    "    \n",
    "    return moviename, first_sub_data, downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtitles_by_list(imdbidlist):\n",
    "\n",
    "    df = pd.DataFrame(columns=['moviename', 'data','file'])\n",
    "\n",
    "    current_date = str.replace(str(date.today()), '-', '_')\n",
    "    current_time = time.strftime('%H_%M_%S', time.localtime())\n",
    "    temporal_txt_path = 'fil_sub_download_temp_file_' + \\\n",
    "        current_date + '_' + current_time + '.csv'\n",
    "\n",
    "    for imdbid in tqdm(imdbidlist):\n",
    "\n",
    "        moviename, first_sub_data, downloaded = get_subtitles_by_id(imdbid)\n",
    "        new_row = pd.DataFrame({'moviename':moviename,'data':str(first_sub_data),'file':str(downloaded)}, index=[imdbid])\n",
    "        df = pd.concat([df.loc[:,:],new_row],)\n",
    "\n",
    "        with open(temporal_txt_path, 'a') as temp_file:\n",
    "            temp_file.write(\n",
    "            ';'.join([str(imdbid), str(moviename), str(first_sub_data), str(downloaded)])+'\\n')\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    df.to_csv('fil_sub_download.csv', sep=';')\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subs to load: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a11b0ae86b4ba3a545fe2ff22594fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subs for Big Girls Don't Cry... They Get Even, imdb_id 101444 not dloaded\n",
      "Subs for Investigating Sex, imdb_id 243991 not dloaded\n",
      "While dloading subs for imdb_id 16544 I got error\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# imdbidlist = ['80339']\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSubs to load: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(imdbidlist)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m get_subtitles_by_list(imdbidlist)\n",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m, in \u001b[0;36mget_subtitles_by_list\u001b[0;34m(imdbidlist)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(temporal_txt_path, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m temp_file:\n\u001b[1;32m     17\u001b[0m         temp_file\u001b[39m.\u001b[39mwrite(\n\u001b[1;32m     18\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(imdbid), \u001b[39mstr\u001b[39m(moviename), \u001b[39mstr\u001b[39m(first_sub_data), \u001b[39mstr\u001b[39m(downloaded)])\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     22\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mfil_sub_download.csv\u001b[39m\u001b[39m'\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ost = OpenSubtitles() \n",
    "cred = eval(open('/home/eva/Diploma/moviesdataset/passwords_1.txt').read())\n",
    "# cred = eval(open('/home/eva/Diploma/moviesdataset/passwords_2.txt').read())\n",
    "ost.login(cred['login'], cred['password'])\n",
    "\n",
    "df_sub_skip = pd.read_csv('fil_sub_download_temp_file.csv', sep=';', names=['imdb_id','moviename', 'data','file'])\n",
    "df_sub_skip = df_sub_skip.astype({'imdb_id': 'int32','moviename': 'string','data': 'object','file': 'object'})\n",
    "df_sub_skip = df_sub_skip.drop_duplicates(subset='imdb_id')\n",
    "df_sub_skip = df_sub_skip.reset_index(drop=True)\n",
    "\n",
    "df_to_sub = pd.read_csv('df_to_sub.csv', sep=';', index_col='id')\n",
    "df_to_sub['imdb_id'] = df_to_sub['imdb_id'].apply(lambda x: x.replace('tt',''))\n",
    "df_to_sub = df_to_sub.astype({'keywords': 'object','title': 'string','imdb_id': 'int32','keywords_len': 'int32'})\n",
    "df_to_sub = df_to_sub[~df_to_sub.imdb_id.isin(df_sub_skip.imdb_id)]\n",
    "df_to_sub = df_to_sub.sort_values(by='id')\n",
    "\n",
    "imdbidlist = df_to_sub.iloc[0:200,:].imdb_id\n",
    "# imdbidlist = ['80339']\n",
    "\n",
    "print(f'Subs to load: {len(imdbidlist)}')\n",
    "\n",
    "get_subtitles_by_list(imdbidlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
